{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Keras-MNIST-Example\" data-toc-modified-id=\"Keras-MNIST-Example-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Keras MNIST Example</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras MNIST Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the keras modules\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras import utils\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some hyper parameters\n",
    "batch_size = 100\n",
    "n_inputs = 784\n",
    "n_classes = 10\n",
    "n_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the two dimensional 28 x 28 pixels\n",
    "#   sized images into a single vector of 784 pixels\n",
    "x_train = x_train.reshape(60000, n_inputs)\n",
    "x_test = x_test.reshape(10000, n_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the input values to float32\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the values of image vectors to fit under 1\n",
    "x_train /= 255\n",
    "x_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert output data into one hot encoded format\n",
    "y_train = utils.to_categorical(y_train, n_classes)\n",
    "y_test = utils.to_categorical(y_test, n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a sequential model\n",
    "model = Sequential()\n",
    "# the first layer has to specify the dimensions of the input vector\n",
    "model.add(Dense(units=128, activation='sigmoid', input_shape=(n_inputs,)))\n",
    "# add dropout layer for preventing overfitting\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=128, activation='sigmoid'))\n",
    "model.add(Dropout(0.1))\n",
    "# output layer can only have the neurons equal to the number of outputs\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# print the summary of our model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 2.3004 - acc: 0.1372\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 2.2269 - acc: 0.2066\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 2.1373 - acc: 0.3014\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 1.9958 - acc: 0.3993\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 1.7929 - acc: 0.4798\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 1.5644 - acc: 0.5524\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 1.3614 - acc: 0.6100\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 1.1991 - acc: 0.6523\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 1.0751 - acc: 0.6896\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.9809 - acc: 0.7151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1609843048>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 40us/step\n",
      "\n",
      " loss: 0.8655913524627685\n",
      "\n",
      " accuracy: 0.7856\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model and print the accuracy score\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('\\n loss:', scores[0])\n",
    "print('\\n accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
