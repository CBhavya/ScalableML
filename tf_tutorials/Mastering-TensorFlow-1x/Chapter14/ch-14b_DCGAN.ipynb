{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks - DCGAN <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy:1.14.5\n",
      "Pandas:0.22.0\n",
      "Matplotlib:2.2.2\n",
      "TensorFlow:1.11.0\n",
      "Keras:2.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "print(\"NumPy:{}\".format(np.__version__))\n",
    "\n",
    "import pandas as pd\n",
    "print(\"Pandas:{}\".format(pd.__version__))\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize']=15,10\n",
    "print(\"Matplotlib:{}\".format(mpl.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(123)\n",
    "print(\"TensorFlow:{}\".format(tf.__version__))\n",
    "\n",
    "import keras\n",
    "print(\"Keras:{}\".format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETSLIB_HOME = '../datasetslib'\n",
    "import sys\n",
    "if not DATASETSLIB_HOME in sys.path:\n",
    "    sys.path.append(DATASETSLIB_HOME)\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import datasetslib\n",
    "\n",
    "from datasetslib import util as dsu\n",
    "datasetslib.datasets_root = os.path.join(os.path.expanduser('~'),'datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-5cbdad85eff8>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /home/ubuntu/datasets/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /home/ubuntu/datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/ubuntu/datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/ubuntu/datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(os.path.join(datasetslib.datasets_root,'mnist'), one_hot=False)\n",
    "\n",
    "x_train = mnist.train.images\n",
    "x_test = mnist.test.images\n",
    "y_train = mnist.train.labels\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "pixel_size = 28\n",
    "\n",
    "def norm(x):\n",
    "    return (x-0.5)/0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_z = 256\n",
    "z_test = np.random.uniform(-1.0,1.0,size=[8,n_z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display the images and labels\n",
    "def display_images(images):\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(1, 8, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DCGAN in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Input, LeakyReLU, Activation\n",
    "from keras.layers import UpSampling2D, Conv2D, Reshape, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "g_in (Dense)                 (None, 3200)              822400    \n",
      "_________________________________________________________________\n",
      "g_in_act (Activation)        (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "g_in_reshape (Reshape)       (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "g_0_up2d (UpSampling2D)      (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "g_0_conv2d (Conv2D)          (None, 10, 10, 64)        204864    \n",
      "_________________________________________________________________\n",
      "g_0_act (Activation)         (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "g_1_up2d (UpSampling2D)      (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "g_1_conv2d (Conv2D)          (None, 20, 20, 32)        51232     \n",
      "_________________________________________________________________\n",
      "g_1_act (Activation)         (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "g_2_up2d (UpSampling2D)      (None, 40, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "g_2_conv2d (Conv2D)          (None, 40, 40, 16)        12816     \n",
      "_________________________________________________________________\n",
      "g_2_act (Activation)         (None, 40, 40, 16)        0         \n",
      "_________________________________________________________________\n",
      "g_out_flatten (Flatten)      (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "g_out (Dense)                (None, 784)               20071184  \n",
      "=================================================================\n",
      "Total params: 21,162,496\n",
      "Trainable params: 21,162,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Discriminator:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "d_0_reshape (Reshape)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "d_0_conv2d (Conv2D)          (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "d_0_act (Activation)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "d_0_maxpool (MaxPooling2D)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "d_out_flatten (Flatten)      (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "d_out (Dense)                (None, 1)                 12545     \n",
      "=================================================================\n",
      "Total params: 14,209\n",
      "Trainable params: 14,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "GAN:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_in (InputLayer)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "g (Sequential)               (None, 784)               21162496  \n",
      "_________________________________________________________________\n",
      "d (Sequential)               (None, 1)                 14209     \n",
      "=================================================================\n",
      "Total params: 21,176,705\n",
      "Trainable params: 21,162,496\n",
      "Non-trainable params: 14,209\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# graph hyperparameters\n",
    "g_learning_rate = 0.00001\n",
    "d_learning_rate = 0.01\n",
    "\n",
    "n_x = 784  # number of pixels in the MNIST image as number of inputs\n",
    "\n",
    "# number of hidden layers for generator and discriminator\n",
    "g_n_layers = 3\n",
    "d_n_layers = 1\n",
    "# filters in each hidden layer\n",
    "g_n_filters = [64,32,16]\n",
    "d_n_filters = [64]\n",
    "\n",
    "\n",
    "n_width=28\n",
    "n_height=28\n",
    "n_depth=1\n",
    "\n",
    "\n",
    "# define generator\n",
    "\n",
    "g_model = Sequential(name='g')\n",
    "g_model.add(Dense(units=5*5*128,  \n",
    "                  input_shape=(n_z,),\n",
    "                  name='g_in'\n",
    "                 ))\n",
    "#g_model.add(BatchNormalization())\n",
    "g_model.add(Activation('tanh',name='g_in_act'))\n",
    "\n",
    "g_model.add(Reshape(target_shape=(5,5,128), \n",
    "                  input_shape=(5*5*128,),\n",
    "                  name='g_in_reshape'\n",
    "                 )\n",
    "         )\n",
    "for i in range(0,g_n_layers):\n",
    "    g_model.add(UpSampling2D(size=[2,2],\n",
    "                             name='g_{}_up2d'.format(i)\n",
    "                            ))\n",
    "    g_model.add(Conv2D(filters=g_n_filters[i],\n",
    "                       kernel_size=(5,5),\n",
    "                       padding='same',\n",
    "                       name='g_{}_conv2d'.format(i)\n",
    "                      ))\n",
    "    g_model.add(Activation('tanh',name='g_{}_act'.format(i)))\n",
    "    \n",
    "g_model.add(Flatten(name='g_out_flatten'))\n",
    "\n",
    "g_model.add(Dense(units=n_x, activation='tanh',name='g_out'))\n",
    "print('Generator:')\n",
    "g_model.summary()\n",
    "g_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=g_learning_rate)\n",
    "             )\n",
    "\n",
    "# define discriminator\n",
    "\n",
    "d_model = Sequential(name='d')\n",
    "d_model.add(Reshape(target_shape=(n_width,n_height,n_depth), \n",
    "                  input_shape=(n_x,),\n",
    "                  name='d_0_reshape'\n",
    "                 )\n",
    "         )\n",
    "\n",
    "\n",
    "for i in range(0,d_n_layers):\n",
    "    d_model.add(Conv2D(filters=d_n_filters[i], \n",
    "                     kernel_size=(5,5), \n",
    "                     padding='same', \n",
    "                     name='d_{}_conv2d'.format(i) \n",
    "                    ) \n",
    "             )\n",
    "    d_model.add(Activation('tanh',name='d_{}_act'.format(i)))\n",
    "\n",
    "    d_model.add(MaxPooling2D(pool_size=(2,2), \n",
    "                             strides=(2,2),\n",
    "                             name='d_{}_maxpool'.format(i)\n",
    "                          ) \n",
    "             )\n",
    "\n",
    "d_model.add(Flatten(name='d_out_flatten'))\n",
    "d_model.add(Dense(units=1, activation='sigmoid',name='d_out'))\n",
    "print('Discriminator:')\n",
    "d_model.summary()\n",
    "d_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(lr=d_learning_rate)\n",
    "             )\n",
    "\n",
    "# define GAN network\n",
    "d_model.trainable=False\n",
    "z_in = Input(shape=(n_z,),name='z_in')\n",
    "x_in = g_model(z_in)\n",
    "gan_out = d_model(x_in)\n",
    "\n",
    "gan_model = Model(inputs=z_in,outputs=gan_out,name='gan')\n",
    "print('GAN:')\n",
    "gan_model.summary()\n",
    "gan_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=g_learning_rate)\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0000   d_loss = 0.565165  g_loss = 1.114490\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0002   d_loss = 0.537465  g_loss = 1.112344\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0004   d_loss = 0.529195  g_loss = 1.171843\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fc054f7693f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mbatch_g_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mepoch_d_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_d_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training hyperparameters\n",
    "\n",
    "n_epochs = 400\n",
    "batch_size = 10\n",
    "#n_batches = int(mnist.train.num_examples / batch_size)\n",
    "n_batches = 100\n",
    "n_epochs_print = 2\n",
    "\n",
    "for epoch in range(n_epochs+1):\n",
    "    epoch_d_loss = 0.0\n",
    "    epoch_g_loss = 0.0\n",
    "    for batch in range(n_batches):\n",
    "        x_batch, _ = mnist.train.next_batch(batch_size)\n",
    "        x_batch = norm(x_batch)\n",
    "        z_batch = np.random.uniform(-1.0,1.0,size=[batch_size,n_z])\n",
    "        g_batch = g_model.predict(z_batch)\n",
    "        \n",
    "        x_in = np.concatenate([x_batch,g_batch])\n",
    "        \n",
    "        y_out = np.ones(batch_size*2)\n",
    "        y_out[:batch_size]=0.9\n",
    "        y_out[batch_size:]=0.1\n",
    "        \n",
    "        d_model.trainable=True\n",
    "        batch_d_loss = d_model.train_on_batch(x_in,y_out)\n",
    "\n",
    "        z_batch = np.random.uniform(-1.0,1.0,size=[batch_size,n_z])\n",
    "        x_in=z_batch\n",
    "        \n",
    "        y_out = np.ones(batch_size)\n",
    "            \n",
    "        d_model.trainable=False\n",
    "        batch_g_loss = gan_model.train_on_batch(x_in,y_out)\n",
    "        \n",
    "        epoch_d_loss += batch_d_loss \n",
    "        epoch_g_loss += batch_g_loss \n",
    "    if epoch % n_epochs_print == 0:\n",
    "        average_d_loss = epoch_d_loss / n_batches\n",
    "        average_g_loss = epoch_g_loss / n_batches\n",
    "        print('epoch: {0:04d}   d_loss = {1:0.6f}  g_loss = {2:0.6f}'\n",
    "              .format(epoch,average_d_loss,average_g_loss))\n",
    "        # predict images using generator model trained            \n",
    "        x_pred = g_model.predict(z_test)\n",
    "        display_images(x_pred.reshape(-1,pixel_size,pixel_size))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
