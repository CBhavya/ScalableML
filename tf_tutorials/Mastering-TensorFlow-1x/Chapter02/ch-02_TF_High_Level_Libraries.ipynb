{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#TF-Estimator-MNIST-Example\" data-toc-modified-id=\"TF-Estimator-MNIST-Example-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>TF Estimator MNIST Example</a></span></li><li><span><a href=\"#TF-Slim-MNIST-Example\" data-toc-modified-id=\"TF-Slim-MNIST-Example-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>TF Slim MNIST Example</a></span></li><li><span><a href=\"#TFLearn-MNIST-Example\" data-toc-modified-id=\"TFLearn-MNIST-Example-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>TFLearn MNIST Example</a></span></li><li><span><a href=\"#Pretty-Tensor-MNIST-Example\" data-toc-modified-id=\"Pretty-Tensor-MNIST-Example-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Pretty Tensor MNIST Example</a></span></li><li><span><a href=\"#Sonnet-MNIST-Example\" data-toc-modified-id=\"Sonnet-MNIST-Example-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Sonnet MNIST Example</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Level Libraries for TensorFlow <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Estimator MNIST Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-4d4e8a4ad79c>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpu2dx99a9\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpu2dx99a9', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f03c44dce10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpu2dx99a9/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.336178, step = 0\n",
      "INFO:tensorflow:global_step/sec: 458.932\n",
      "INFO:tensorflow:loss = 1.3091612, step = 100 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.737\n",
      "INFO:tensorflow:loss = 1.024315, step = 200 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 519.173\n",
      "INFO:tensorflow:loss = 0.63515806, step = 300 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.562\n",
      "INFO:tensorflow:loss = 0.6312326, step = 400 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.692\n",
      "INFO:tensorflow:loss = 0.31829822, step = 500 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.936\n",
      "INFO:tensorflow:loss = 0.4717928, step = 600 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.853\n",
      "INFO:tensorflow:loss = 0.42981514, step = 700 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.746\n",
      "INFO:tensorflow:loss = 0.37306762, step = 800 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.103\n",
      "INFO:tensorflow:loss = 0.43396065, step = 900 (0.193 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpu2dx99a9/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.43270615.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-29-18:28:04\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpu2dx99a9/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-29-18:28:05\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.8892, global_step = 1000, loss = 0.3917611\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/tmpu2dx99a9/model.ckpt-1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8892, 'loss': 0.3917611, 'global_step': 1000}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "mnist = input_data.read_data_sets(os.path.join('.', 'mnist'),\n",
    "                                  one_hot=False\n",
    "                                  )\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "n_classes = 10\n",
    "batch_size = 100\n",
    "n_steps = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode):\n",
    "    \"\"\" define the model function\n",
    "    \"\"\"\n",
    "    espec_op = tf.estimator.EstimatorSpec\n",
    "    # features is a dict as per Estimator specifications\n",
    "    x = features['images']\n",
    "    # define the network\n",
    "    layer_1 = tf.layers.dense(x, 32)\n",
    "    layer_2 = tf.layers.dense(layer_1, 32)\n",
    "    logits = tf.layers.dense(layer_2, n_classes)\n",
    "\n",
    "    # define predicted classes\n",
    "    predicted_classes = tf.argmax(logits, axis=1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        espec = espec_op(mode,\n",
    "                         predictions=predicted_classes\n",
    "                         )\n",
    "    else:\n",
    "        # define loss and optimizer\n",
    "        entropy_op = tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "        loss_op = tf.reduce_mean(entropy_op(logits=logits,\n",
    "                                            labels=tf.cast(labels,\n",
    "                                                           dtype=tf.int32)\n",
    "                                            )\n",
    "                                 )\n",
    "        optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss_op, global_step=tf.train.get_global_step())\n",
    "\n",
    "        # define accuracy\n",
    "        accuracy_op = tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predicted_classes)\n",
    "\n",
    "        espec = espec_op(mode=mode,\n",
    "                         predictions=predicted_classes,\n",
    "                         loss=loss_op,\n",
    "                         train_op=train_op,\n",
    "                         eval_metric_ops={'accuracy': accuracy_op}\n",
    "                         )\n",
    "\n",
    "    return espec\n",
    "\n",
    "\n",
    "# create estimator object\n",
    "model = tf.estimator.Estimator(model_fn)\n",
    "\n",
    "# train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': x_train},\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "model.train(train_input_fn, steps=n_steps)\n",
    "\n",
    "# evaluate the model\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': x_test},\n",
    "    y=y_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "model.evaluate(eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Slim MNIST Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/learning.py:737: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path ./slim_logs/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:global step 99: loss = 2.2202 (0.011 sec/step)\n",
      "INFO:tensorflow:global step 199: loss = 2.1271 (0.012 sec/step)\n",
      "INFO:tensorflow:global step 299: loss = 2.0339 (0.012 sec/step)\n",
      "INFO:tensorflow:global step 399: loss = 1.9436 (0.012 sec/step)\n",
      "INFO:tensorflow:global step 499: loss = 1.8618 (0.012 sec/step)\n",
      "INFO:tensorflow:global step 599: loss = 1.7912 (0.011 sec/step)\n",
      "INFO:tensorflow:global step 699: loss = 1.7242 (0.012 sec/step)\n",
      "INFO:tensorflow:global step 799: loss = 1.6656 (0.012 sec/step)\n",
      "INFO:tensorflow:global step 899: loss = 1.6157 (0.011 sec/step)\n",
      "INFO:tensorflow:global step 999: loss = 1.5671 (0.011 sec/step)\n",
      "INFO:tensorflow:Stopping Training.\n",
      "INFO:tensorflow:Finished training! Saving model to disk.\n",
      "final loss=1.5671383142471313\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.contrib import slim\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_classes = 10  \n",
    "n_steps = 1000\n",
    "\n",
    "# let us get the data\n",
    "mnist = input_data.read_data_sets(os.path.join('.', 'mnist'), one_hot=True)\n",
    "\n",
    "X_train = mnist.train.images\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "Y_train = mnist.train.labels\n",
    "Y_train = tf.convert_to_tensor(Y_train)\n",
    "\n",
    "\n",
    "def mlp(x):\n",
    "    net = slim.fully_connected(x, 32, scope='fc1')\n",
    "    net = slim.dropout(net, 0.5, scope='dropout1')\n",
    "    net = slim.fully_connected(net, 32, scope='fc2')\n",
    "    net = slim.dropout(net, 0.5, scope='dropout2')\n",
    "    net = slim.fully_connected(net, n_classes, activation_fn=None, scope='fc3')\n",
    "    return net\n",
    "\n",
    "\n",
    "# Define the model\n",
    "logits = mlp(X_train)\n",
    "\n",
    "# Define the loss functions and get the total loss\n",
    "loss = tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=Y_train)\n",
    "total_loss = tf.losses.get_total_loss()\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "train_op = slim.learning.create_train_op(total_loss, optimizer)\n",
    "\n",
    "# Run the training\n",
    "final_loss = slim.learning.train(\n",
    "    train_op,\n",
    "    logdir='./slim_logs',\n",
    "    number_of_steps=n_steps,\n",
    "    log_every_n_steps=100)\n",
    "\n",
    "print('final loss={}'.format(final_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFLearn MNIST Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5499  | total loss: \u001b[1m\u001b[32m0.40155\u001b[0m\u001b[0m | time: 2.719s\n",
      "| Adam | epoch: 010 | loss: 0.40155 - acc: 0.9006 -- iter: 54900/55000\n",
      "Training Step: 5500  | total loss: \u001b[1m\u001b[32m0.38456\u001b[0m\u001b[0m | time: 2.724s\n",
      "| Adam | epoch: 010 | loss: 0.38456 - acc: 0.9045 -- iter: 55000/55000\n",
      "--\n",
      "Test accuracy: 0.9157\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "import tflearn\n",
    "import tflearn.datasets.mnist as mnist\n",
    "import os\n",
    "\n",
    "batch_size = 100\n",
    "n_classes = 10\n",
    "n_epochs = 10\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = mnist.load_data(\n",
    "    data_dir=os.path.join('.', 'mnist'), one_hot=True)\n",
    "\n",
    "# Build deep neural network\n",
    "input_layer = tflearn.input_data(shape=[None, 784])\n",
    "layer1 = tflearn.fully_connected(input_layer,\n",
    "                                 10,\n",
    "                                 activation='relu'\n",
    "                                 )\n",
    "layer2 = tflearn.fully_connected(layer1,\n",
    "                                 10,\n",
    "                                 activation='relu'\n",
    "                                 )\n",
    "output = tflearn.fully_connected(layer2,\n",
    "                                 n_classes,\n",
    "                                 activation='softmax'\n",
    "                                 )\n",
    "\n",
    "net = tflearn.regression(output,\n",
    "                         optimizer='adam',\n",
    "                         metric=tflearn.metrics.Accuracy(),\n",
    "                         loss='categorical_crossentropy'\n",
    "                         )\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    n_epoch=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    show_metric=True,\n",
    "    run_id='dense_model')\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sonnet MNIST Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dm-sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n",
      "Epoch : 0 Training Loss : 235.4683074951172\n",
      "Epoch : 1 Training Loss : 224.77963256835938\n",
      "Epoch : 2 Training Loss : 224.72128295898438\n",
      "Epoch : 3 Training Loss : 212.39328002929688\n",
      "Epoch : 4 Training Loss : 216.31341552734375\n",
      "Epoch : 5 Training Loss : 210.68519592285156\n",
      "Epoch : 6 Training Loss : 204.42543029785156\n",
      "Epoch : 7 Training Loss : 200.62547302246094\n",
      "Epoch : 8 Training Loss : 201.35716247558594\n",
      "Epoch : 9 Training Loss : 188.47499084472656\n",
      "Test loss : 181.6931610107422\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "import os\n",
    "import sonnet as snt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "class MNIST(snt.AbstractModule):\n",
    "\n",
    "    def __init__(self, mnist_part, batch_size, name='MNIST'):\n",
    "\n",
    "        super(MNIST, self).__init__(name=name)\n",
    "\n",
    "        self._X = tf.constant(mnist_part.images, dtype=tf.float32)\n",
    "        self._Y = tf.constant(mnist_part.labels, dtype=tf.float32)\n",
    "        self._batch_size = batch_size\n",
    "        self._M = mnist_part.num_examples\n",
    "\n",
    "    def _build(self):\n",
    "        idx = tf.random_uniform([self._batch_size], 0, self._M, tf.int64)\n",
    "        X = tf.gather(self._X, idx)\n",
    "        Y = tf.gather(self._Y, idx)\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "class MLP(snt.AbstractModule):\n",
    "    def __init__(self, output_sizes, name='mlp'):\n",
    "        super(MLP, self).__init__(name=name)\n",
    "\n",
    "        self._layers = []\n",
    "\n",
    "        for output_size in output_sizes:\n",
    "            self._layers.append(snt.Linear(output_size=output_size))\n",
    "\n",
    "    def _build(self, X):\n",
    "\n",
    "        # add the input layer\n",
    "        model = tf.sigmoid(self._layers[0](X))\n",
    "\n",
    "        # add hidden layers\n",
    "        for i in range(1, len(self._layers) - 1):\n",
    "            model = tf.sigmoid(self._layers[i](model))\n",
    "\n",
    "        # add output layer\n",
    "        model = tf.nn.softmax(self._layers[len(self._layers) - 1](model))\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "n_classes = 10\n",
    "n_epochs = 10\n",
    "\n",
    "mnist = input_data.read_data_sets(os.path.join('.', 'mnist'),\n",
    "                                  one_hot=True\n",
    "                                  )\n",
    "train = MNIST(mnist.train, batch_size=batch_size)\n",
    "test = MNIST(mnist.test, batch_size=batch_size)\n",
    "\n",
    "X_train, Y_train = train()\n",
    "X_test, Y_test = test()\n",
    "\n",
    "model = MLP([20, n_classes])\n",
    "\n",
    "Y_train_hat = model(X_train)\n",
    "Y_test_hat = model(X_test)\n",
    "\n",
    "\n",
    "def loss(Y_hat, Y):\n",
    "    return -tf.reduce_sum(Y * tf.log(Y_hat))\n",
    "\n",
    "\n",
    "L_train = loss(Y_train_hat, Y_train)\n",
    "L_test = loss(Y_test_hat, Y_test)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(\n",
    "    learning_rate=0.01).minimize(L_train)\n",
    "\n",
    "with tf.Session() as tfs:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        loss_val, _ = tfs.run((L_train, optimizer))\n",
    "        print('Epoch : {} Training Loss : {}'.format(epoch, loss_val))\n",
    "\n",
    "    loss_val = tfs.run(L_test)\n",
    "    print('Test loss : {}'.format(loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
