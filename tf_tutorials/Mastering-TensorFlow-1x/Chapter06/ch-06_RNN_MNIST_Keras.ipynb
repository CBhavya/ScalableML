{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notes are from Fandango, Armando. Mastering TensorFlow 1.x: Advanced machine learning and deep learning concepts using TensorFlow 1.x and Keras (Kindle Locations 2602-2604). Packt Publishing. Kindle Edition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for MNIST with TensorFlow and Keras <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although RNN is mostly used for sequence data, it can also be used for image data. We know that images have minimum two dimensions - height and width. Now think of one of the dimensions as time steps, and other as features. For MNIST, the image size is 28 x 28 pixels, thus we can think of an MNIST image as having 28 time steps with 28 features in each timestep.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy:1.14.5\n",
      "TensorFlow:1.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "print(\"NumPy:{}\".format(np.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(123)\n",
    "print(\"TensorFlow:{}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETSLIB_HOME = '../datasetslib'\n",
    "import sys\n",
    "if not DATASETSLIB_HOME in sys.path:\n",
    "    sys.path.append(DATASETSLIB_HOME)\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import datasetslib\n",
    "\n",
    "datasetslib.datasets_root = os.path.join(os.path.expanduser('~'),'datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-98091e9a151e>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /home/ubuntu/datasets/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /home/ubuntu/datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /home/ubuntu/datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/ubuntu/datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(os.path.join(datasetslib.datasets_root,\n",
    "                                               'mnist'), \n",
    "                                  one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784) (55000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "Y_train = mnist.train.labels\n",
    "Y_test = mnist.test.labels\n",
    "n_classes = 10\n",
    "print(X_train.shape,Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Transform the data from 784 pixels in 1-D to 28 x 28 pixels in 2-D:\n",
    "X_train = X_train.reshape(-1,28,28)\n",
    "X_test = X_test.reshape(-1,28,28)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN With Keras for MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 16)                720       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 890\n",
      "Trainable params: 890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create and fit the SimpleRNN model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=16, activation='relu', input_shape=(28,28)))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with categorical_crossentropy loss, accuracy metric, and RMSprop optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.01),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 11s 205us/step - loss: 1.2187 - acc: 0.5543\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 10s 189us/step - loss: 0.8951 - acc: 0.6861\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 10s 189us/step - loss: 0.8283 - acc: 0.7093\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 10s 189us/step - loss: 0.7828 - acc: 0.7245\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 10s 189us/step - loss: 0.7557 - acc: 0.7363\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 10s 190us/step - loss: 0.7491 - acc: 0.7457\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 10s 190us/step - loss: 0.7059 - acc: 0.7710\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 10s 190us/step - loss: 0.6617 - acc: 0.7914\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 10s 189us/step - loss: 0.6358 - acc: 0.8051\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 10s 189us/step - loss: 0.5969 - acc: 0.8192\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 10s 190us/step - loss: 0.5744 - acc: 0.8325\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 10s 189us/step - loss: 0.5523 - acc: 0.8395\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 10s 190us/step - loss: 0.5460 - acc: 0.8425\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 11s 196us/step - loss: 0.5565 - acc: 0.8369\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 10s 189us/step - loss: 0.5483 - acc: 0.8383\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 10s 189us/step - loss: 0.5458 - acc: 0.8381\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 10s 190us/step - loss: 0.5459 - acc: 0.8432\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 10s 189us/step - loss: 0.5294 - acc: 0.8452\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 10s 189us/step - loss: 0.5389 - acc: 0.8438\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 10s 189us/step - loss: 0.5411 - acc: 0.8422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feed0446400>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training. It might take a few minutes\n",
    "model.fit(X_train, Y_train,\n",
    "                    batch_size=100,\n",
    "                    epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 361us/step\n",
      "\n",
      "Test loss: 0.447122533094883\n",
      "Test accuracy: 0.8678\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print('\\nTest loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
