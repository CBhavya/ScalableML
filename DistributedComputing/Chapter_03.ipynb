{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelism in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will look at parallel programming in more detail and see which \n",
    "facilities Python offers us to make our code use more than one CPU or CPU core at the \n",
    "time (but always within the boundaries of a single machine). \n",
    "\n",
    "The main goal here will be speed for CPU-intensive problems, and responsiveness for I/O-intensive code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by writing a simple program that makes use of multiple threads to \n",
    "download data from the Web. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We start by importing the modules we need from the Standard Library (that is, threading, queue, and urllib.request).\n",
    "\n",
    "from time import time\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "links.append('https://www.stats.govt.nz/assets/Uploads/Annual-enterprise-survey/Annual-enterprise-survey-2017-financial-year-provisional/Download-data/annual-enterprise-survey-2017-financial-year-provisional-size-bands-csv.csv')\n",
    "links.append('https://www.stats.govt.nz/assets/Uploads/Household-living-costs-price-indexes/Household-living-costs-price-indexes-September-2018-quarter/Download-data/household-living-costs-price-indexes-sep18qtr-time-series-indexes.csv')\n",
    "links.append('https://www.stats.govt.nz/assets/Uploads/Annual-enterprise-survey/Annual-enterprise-survey-2017-financial-year-provisional/Download-data/annual-enterprise-survey-2017-financial-year-provisional-csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.stats.govt.nz/assets/Uploads/Annual-enterprise-survey/Annual-enterprise-survey-2017-financial-year-provisional/Download-data/annual-enterprise-survey-2017-financial-year-provisional-size-bands-csv.csv',\n",
       " 'https://www.stats.govt.nz/assets/Uploads/Household-living-costs-price-indexes/Household-living-costs-price-indexes-September-2018-quarter/Download-data/household-living-costs-price-indexes-sep18qtr-time-series-indexes.csv',\n",
       " 'https://www.stats.govt.nz/assets/Uploads/Annual-enterprise-survey/Annual-enterprise-survey-2017-financial-year-provisional/Download-data/annual-enterprise-survey-2017-financial-year-provisional-csv.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(act_url, outq):\n",
    "    with urllib.request.urlopen(act_url) as res:\n",
    "        body = res.read()\n",
    "    outq.put((act_url, body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a thread-safe queue (that is, an instance of Queue from the Python queue module)\n",
    "# We call this queue outputq. It will hold the data produced by the various threads that downloaded the contents of the the websites. \n",
    "\n",
    "outputq = Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Once we have the output queue, we then spawn a new worker thread for each website link. \n",
    "#Each worker thread simply runs the get_content function, with the actual link and the output queue as arguments.\n",
    "\n",
    "for link in links:\n",
    "        t = Thread(target=get_content,\n",
    "                   kwargs={'act_url': link,\n",
    "                           'outq': outputq})\n",
    "        t.daemon = True\n",
    "        t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these threads are just fire and forget threads, we can make them daemons, meaning that the main Python program \n",
    "will not wait for them to quit (join in  thread parlance) before exiting.\n",
    "It is quite important to get this last observation about daemon threads and queues \n",
    "right. The main difficulty in using threads to perform actions in parallel is that we \n",
    "cannot tell when a given thread will read or write any data shared with other threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can give rise to what is usually called a race condition. This is the situation where \n",
    "on one hand, the correct execution of the system depends on some actions being \n",
    "performed in a given order, and on the other hand, these actions are not guaranteed to \n",
    "happen in the right order, that is, the order envisioned by the programmer.\n",
    "\n",
    "One way out of synchronization problems like these is the use of locks. Thread-safe \n",
    "queues are a very convenient example of lock-based data structures that we can use \n",
    "to organize data access.\n",
    "\n",
    "Since each thread writes to the same output queue, we might just as well monitor \n",
    "that queue to know when results are ready and it is time to quit. \n",
    "\n",
    "Here, we do that by simply fetching one result from the queue per link \n",
    "(the loop over links) and by waiting for the queue to join (outputq.join()), \n",
    "which will happen when all the results have been fetched (more precisely, when each \n",
    "get() method is followed by a call to task_done()). This way, we are sure that our \n",
    "program does not quit prematurely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.stats.govt.nz/assets/Uploads/Annual-enterprise-survey/Annual-enterprise-survey-2017-financial-year-provisional/Download-data/annual-enterprise-survey-2017-financial-year-provisional-size-bands-csv.csv b'year,industry_code_ANZSIC,industry_name_ANZSIC,rme_size_grp,variable,value,unit\\r\\n2011,A,\"Agriculture'\n",
      "https://www.stats.govt.nz/assets/Uploads/Household-living-costs-price-indexes/Household-living-costs-price-indexes-September-2018-quarter/Download-data/household-living-costs-price-indexes-sep18qtr-time-series-indexes.csv b'hlpi_name,series_ref,quarter,hlpi,nzhec,nzhec_name,nzhec_short,level,index,change.q,change.a\\r\\nAll ho'\n",
      "https://www.stats.govt.nz/assets/Uploads/Annual-enterprise-survey/Annual-enterprise-survey-2017-financial-year-provisional/Download-data/annual-enterprise-survey-2017-financial-year-provisional-csv.csv b'Year,Industry_aggregation_NZSIOC,Industry_code_NZSIOC,Industry_name_NZSIOC,Units,Variable_code,Varia'\n"
     ]
    }
   ],
   "source": [
    "for _ in links:\n",
    "    link, body = outputq.get()\n",
    "    print(link, body[:100])\n",
    "    outputq.task_done()\n",
    "outputq.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6709909439086914\n"
     ]
    }
   ],
   "source": [
    "# no threads\n",
    "q = Queue()\n",
    "t0 = time(); [get_content(p, q) for p in links]; dt = time() - t0; print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32817721366882324\n"
     ]
    }
   ],
   "source": [
    "# threads can help!\n",
    "\n",
    "t0 = time();\n",
    "\n",
    "for link in links:\n",
    "        t = Thread(target=get_content,\n",
    "                   kwargs={'act_url': link,\n",
    "                           'outq': outputq})\n",
    "        t.daemon = True\n",
    "        t.start()\n",
    "        \n",
    "for _ in links:\n",
    "    link, body = outputq.get()\n",
    "    #print(link, body[:100])\n",
    "    outputq.task_done()\n",
    "outputq.join()\n",
    "\n",
    "dt = time() - t0; print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Somtimes threads can hurt performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    if n <= 2:\n",
    "        return 1\n",
    "    elif n == 0:\n",
    "        return 0\n",
    "    elif n < 0:\n",
    "        raise Exception('fib(n) is undefined for n < 0')\n",
    "    return fib(n - 1) + fib(n - 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runthreads(threadnum,fibnum):\n",
    "    t0 = time();\n",
    "    for i in range(threadnum):\n",
    "            t = Thread(target=fib, args=(fibnum, ))\n",
    "            t.start()\n",
    "    dt = time() - t0; \n",
    "    print(dt/threadnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005498409271240234\n",
      "0.007891654968261719\n",
      "0.01589663823445638\n",
      "0.014477372169494629\n",
      "0.023003339767456055\n"
     ]
    }
   ],
   "source": [
    "# these numbers should be the same if threads were parallel\n",
    "\n",
    "runthreads(1,34)\n",
    "runthreads(2,34)\n",
    "runthreads(3,34)\n",
    "runthreads(4,34)\n",
    "runthreads(8,34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! The use of two threads to compute the 34 Fibonacci number in parallel \n",
    "takes twice as much time as using a single thread to do the same computation once. \n",
    "Increasing the number of parallel computations just increases the execution time \n",
    "linearly. Clearly, something is not quite right, as we would have expected the threads \n",
    "to run in parallel (again, on a quad-core machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that there is something not obvious going on deep inside the Python \n",
    "interpreter that is affecting our CPU-bound threads. That thing is called Global \n",
    "Interpreter Lock (GIL). As the name implies, the GIL is a global lock that is used, \n",
    "mostly, to keep reference counting sane (remember when we talked about that a little \n",
    "while ago?). The consequence of the GIL is that even though Python threads are real \n",
    "OS-native threads, only one of them can be active at any given point in time.\n",
    "\n",
    "This has led some to say that the Python interpreter is a single-threaded interpreter, \n",
    "which is not quite true. However, this statement is also, conceptually at least, not \n",
    "completely wrong either. \n",
    "\n",
    "The situation we just witnessed is very similar to the \n",
    "behavior we observed when writing coroutines. In that case, in fact, only one piece \n",
    "of code could run at any given point in time. Things just work, meaning we get the \n",
    "parallelism that we expect, when one coroutine or thread waits for I/O and another \n",
    "one takes over the CPU. Things do not work as well in terms of performance speedups, \n",
    "when one task needs the CPU for a long time, as is the case with CPU-bound tasks as \n",
    "in the Fibonacci example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with coroutines, using threads in Python is far from being a lost cause. \n",
    "Parallel I/O can give a significant performance boost to our application, both in the \n",
    "case of code using multiple threads or coroutines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, not all Python interpreters have the GIL; Jython, for instance, does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple processes\n",
    "Traditionally, the way Python programmers have worked around the GIL and its \n",
    "effect on CPU-bound threads has been to use multiple processes instead of multiple \n",
    "threads. This approach (multiprocessing) has some disadvantages, which mostly boil \n",
    "down to having to launch multiple instances of the Python interpreter with all the \n",
    "startup time and memory usage penalties that this implies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "psutil.cpu_count(logical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.cpu_count(logical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using multiple processes to execute tasks in parallel has some nice properties. \n",
    "\n",
    "Multiple processes have their own memory space and \n",
    "implement a share-nothing architecture and they also allow us to (more) easily transition from a single-machine \n",
    "architecture to a distributed application, where one would have to use multiple \n",
    "processes (on different machines) anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main modules in the Python Standard Library that we can use to \n",
    "implement process-based parallelism, and both of them are truly excellent. One is \n",
    "called multiprocessing and the other is concurrent.futures. The concurrent.\n",
    "futures module is built on top of multiprocessing and the threading module and \n",
    "provides a powerful high-level interface to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n):\n",
    "    if n <= 2:\n",
    "        return 1\n",
    "    elif n == 0:\n",
    "        return 0\n",
    "    elif n < 0:\n",
    "        raise Exception('fib(n) is undefined for n < 0')\n",
    "        return fib(n - 1) + fib(n - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runprocesses(workernum,fibnum):\n",
    "    t0 = time();\n",
    "    \n",
    "    with cf.ProcessPoolExecutor(max_workers=workernum) as pool:\n",
    "            results = pool.map(fib, [fibnum] * workernum)\n",
    "    \n",
    "    dt = time() - t0; \n",
    "    print(dt/workernum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the ProcessPoolExecutor class exported by concurrent.futures. \n",
    "\n",
    "This is one of the two main classes exported by \n",
    "the module, the other being ThreadPoolExecutor, which is used to create a pool of \n",
    "threads, instead of a pool of processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013290166854858398\n",
      "0.007574319839477539\n",
      "0.0073473453521728516\n",
      "0.007063925266265869\n",
      "***************\n",
      "0.006812989711761475\n",
      "0.007418349385261536\n",
      "0.006722554564476013\n"
     ]
    }
   ],
   "source": [
    "runprocesses(1,34)\n",
    "runprocesses(2,34)\n",
    "runprocesses(3,34)\n",
    "runprocesses(4,34)\n",
    "print('***************')\n",
    "runprocesses(8,34)\n",
    "runprocesses(16,34)\n",
    "runprocesses(32,34)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both, ProcessPoolExecutor and ThreadPoolExecutor have the same fundamental API (and in fact, they are both subclasses of the same class): they have three main \n",
    "methods, which are as follows:\n",
    "\n",
    "• submit(f, *args, **kwargs): This is used to schedule an asynchronous \n",
    "call to f(*args, **kwargs) and return a Future instance as a result \n",
    "placeholder.\n",
    "\n",
    "• map(f, *arglist, timeout=None, chunksize=1): This is the equivalent \n",
    "to the built-in map(f, *arglist) method. It returns a list of Future objects \n",
    "rather than a list of actual results, as map would do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third method, shutdown(wait=True) is used to free the resources used by  \n",
    "the Executor object as soon as all currently scheduled functions are done. It waits  \n",
    "(if wait=True) until that happens. Using an Executor object after a call to this \n",
    "method will raise a RuntimeError exception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executor objects can also be used as context managers (as we are, in the preceding \n",
    "example, using with cf.ProcessPoolExecutor(max_workers=args.n) as pool \n",
    "construct). In those cases, there is an implicit blocking call made to the Executor \n",
    "shutdown method on the context manager's exit. This means that if we were to access \n",
    "the results list, we would get integers rather than Future instances once the context \n",
    "manager exits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Future instance, the other main class exported by the concurrent.futures \n",
    "package, is a placeholder for the result of an asynchronous call. We can check \n",
    "whether the call is still running, whether or not it raised an exception, and so on.  \n",
    "We call a Future instance result() method to access (with an optional timeout)  \n",
    "its value once it is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = ProcessPoolExecutor(max_workers=1)\n",
    "fut = pool.submit(fib, 38)\n",
    "fut.running()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fut.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut.result(timeout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut.result(timeout=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw how to use the concurrent.futures package to create a worker pool (using the ProcessPoolExecutor class) and submit \n",
    "work to it (pool.submit(fib, 38)). As we expect, submit returns a Future object \n",
    "(fut in the preceding code), which is a placeholder for a result that is not yet available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _chain_from_iterable_of_lists at 0x7f9d24180780>\n"
     ]
    }
   ],
   "source": [
    "workernum=1\n",
    "fibnum=38\n",
    "with cf.ProcessPoolExecutor(max_workers=workernum) as pool:\n",
    "            results = pool.map(fib, [fibnum] * workernum)\n",
    "            print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a one-line modification to our process-based parallel code and \n",
    "switch to using threads instead; simply replace ProcessPoolExecutor with \n",
    "ThreadPoolExecutor. For a quick example, change the previous script (mpfib.py), \n",
    "replacing the following line:\n",
    "with cf. ProcessPoolExecutor (max_workers=args.n) as pool:\n",
    "Replace the preceding line with this one:\n",
    "with cf.ThreadPoolExecutor(max_workers=args.n) as pool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Executor.map.<locals>.result_iterator at 0x7f9d241337d8>\n"
     ]
    }
   ],
   "source": [
    "threadnum=1\n",
    "fibnum=38\n",
    "with cf.ThreadPoolExecutor(max_workers=threadnum) as pool:\n",
    "    results = pool.map(fib, [fibnum] * workernum)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocess queues\n",
    "When using multiple processes, the issue that comes up is how to exchange data \n",
    "between the workers. The multiprocessing module offers a mechanism to do that \n",
    "in the form of queues and pipes. Hence, we are going to look at multiprocess queues.\n",
    "The multiprocessing.Queue class is modeled after the queue.Queue class with the \n",
    "additional twist that items stored in the multiprocessing queue need to be pickable. \n",
    "To illustrate how to use these queues, create a new Python script (queues.py) with \n",
    "the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
