{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqlContext = org.apache.spark.sql.SQLContext@504f5509\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one deprecation warning; re-run with -deprecation for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SQLContext@504f5509"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATAFRAME STATISTICS TUTORIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfQuestionsCSV = [id: int, creation_date: string ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: int, creation_date: string ... 5 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create a dataframe from questions file questions_10K.csv\n",
    "  val dfQuestionsCSV = spark\n",
    "    .read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"dateFormat\",\"yyyy-MM-dd HH:mm:ss\")\n",
    "    .csv(\"../resources/questions_10K.csv\")\n",
    "    .toDF(\"id\", \"creation_date\", \"closed_date\", \"deletion_date\", \"score\", \"owner_userid\", \"answer_count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfQuestions = [id: int, creation_date: timestamp ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: int, creation_date: timestamp ... 5 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// cast columns to data types\n",
    "  val dfQuestions = dfQuestionsCSV.select(\n",
    "    dfQuestionsCSV.col(\"id\").cast(\"integer\"),\n",
    "    dfQuestionsCSV.col(\"creation_date\").cast(\"timestamp\"),\n",
    "    dfQuestionsCSV.col(\"closed_date\").cast(\"timestamp\"),\n",
    "    dfQuestionsCSV.col(\"deletion_date\").cast(\"date\"),\n",
    "    dfQuestionsCSV.col(\"score\").cast(\"integer\"),\n",
    "    dfQuestionsCSV.col(\"owner_userid\").cast(\"integer\"),\n",
    "    dfQuestionsCSV.col(\"answer_count\").cast(\"integer\")\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:37: error: not found: value avg\n",
       "           .select(avg(\"score\"))\n",
       "                   ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Average\n",
    "//  import org.apache.spark.sql.functions._\n",
    "  dfQuestions\n",
    "    .select(avg(\"score\"))\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:55: error: not found: value sum\n",
       "           .select(sum(\"score\"))\n",
       "                   ^\n",
       "<console>:35: error: not found: value max\n",
       "           .select(max(\"score\"))\n",
       "                   ^\n",
       "<console>:41: error: not found: value min\n",
       "           .select(min(\"score\"))\n",
       "                   ^\n",
       "<console>:47: error: not found: value mean\n",
       "           .select(mean(\"score\"))\n",
       "                   ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  // Maximum\n",
    "  dfQuestions\n",
    "    .select(max(\"score\"))\n",
    "    .show()\n",
    "\n",
    "\n",
    "  // Minimum\n",
    "  dfQuestions\n",
    "    .select(min(\"score\"))\n",
    "    .show()\n",
    "\n",
    "\n",
    "  // Mean\n",
    "  dfQuestions\n",
    "    .select(mean(\"score\"))\n",
    "    .show()\n",
    "\n",
    "\n",
    "  // Sum\n",
    "  dfQuestions\n",
    "    .select(sum(\"score\"))\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 40:=========================================>            (153 + 4) / 199]+------------+----------+-----------------+\n",
      "|owner_userid|avg(score)|max(answer_count)|\n",
      "+------------+----------+-----------------+\n",
      "|         268|      26.0|                1|\n",
      "|         136|      57.6|                9|\n",
      "|         123|      20.0|                3|\n",
      "+------------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " // Group by with statistics\n",
    "  dfQuestions\n",
    "    .filter(\"id > 400 and id < 450\")\n",
    "    .filter(\"owner_userid is not null\")\n",
    "    .join(dfTags, dfQuestions.col(\"id\").equalTo(dfTags(\"id\")))\n",
    "    .groupBy(dfQuestions.col(\"owner_userid\"))\n",
    "    .agg(avg(\"score\"), max(\"answer_count\"))\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-----------------+------------------+\n",
      "|summary|               id|             score|     owner_userid|      answer_count|\n",
      "+-------+-----------------+------------------+-----------------+------------------+\n",
      "|  count|             9999|              9999|             7388|              9922|\n",
      "|   mean|33929.17081708171| 36.14631463146315|47389.99472116947|6.6232614392259626|\n",
      "| stddev|19110.09560532429|160.48316753972045|280943.1070344427| 9.069109116851138|\n",
      "|    min|                1|               -27|                1|                -5|\n",
      "|    max|            66037|              4443|          3431280|               316|\n",
      "+-------+-----------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfQuestionsStatistics = [summary: string, id: string ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[summary: string, id: string ... 3 more fields]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// DataFrame Statistics using describe() method\n",
    "  val dfQuestionsStatistics = dfQuestions.describe()\n",
    "  dfQuestionsStatistics.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation between column score and answer_count = 0.3699847903294707\n",
      "covariance between column score and answer_count = 537.513381444165\n",
      "+----------------------+\n",
      "|answer_count_freqItems|\n",
      "+----------------------+\n",
      "|  [23, 131, 77, 86,...|\n",
      "+----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "correlation = 0.3699847903294707\n",
       "covariance = 537.513381444165\n",
       "dfFrequentScore = [answer_count_freqItems: array<int>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[answer_count_freqItems: array<int>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " // Correlation\n",
    "  val correlation = dfQuestions.stat.corr(\"score\", \"answer_count\")\n",
    "  println(s\"correlation between column score and answer_count = $correlation\")\n",
    "\n",
    "\n",
    "  // Covariance\n",
    "  val covariance = dfQuestions.stat.cov(\"score\", \"answer_count\")\n",
    "  println(s\"covariance between column score and answer_count = $covariance\")\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " // Frequent Items\n",
    "  val dfFrequentScore = dfQuestions.stat.freqItems(Seq(\"answer_count\"))\n",
    "  dfFrequentScore.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+---+---+---+---+---+---+---+---+---+\n",
      "|score_owner_userid|  1| 11| 13| 17|  2|  3|  4|  5|  8|  9|\n",
      "+------------------+---+---+---+---+---+---+---+---+---+---+\n",
      "|                56|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|\n",
      "|               472|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|\n",
      "|                14|  0|  0|  0|  1|  0|  0|  0|  1|  0|  0|\n",
      "|                20|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|\n",
      "|               179|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|\n",
      "|                84|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|\n",
      "|               160|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                21|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|\n",
      "|                 9|  0|  0|  0|  0|  0|  0|  1|  1|  0|  0|\n",
      "|                 2|  0|  0|  0|  0|  0|  0|  0|  1|  0|  1|\n",
      "+------------------+---+---+---+---+---+---+---+---+---+---+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------------+-----+\n",
      "|answer_count|count|\n",
      "+------------+-----+\n",
      "|          20|   34|\n",
      "|           5|  811|\n",
      "|          10|  272|\n",
      "+------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfScoreByUserid = [score_owner_userid: string, 1: bigint ... 9 more fields]\n",
       "dfQuestionsByAnswerCount = [id: int, creation_date: timestamp ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: int, creation_date: timestamp ... 5 more fields]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Crosstab\n",
    "  val dfScoreByUserid = dfQuestions\n",
    "    .filter(\"owner_userid > 0 and owner_userid < 20\")\n",
    "    .stat\n",
    "    .crosstab(\"score\", \"owner_userid\")\n",
    "  dfScoreByUserid.show(10)\n",
    "\n",
    "\n",
    "  // Stratified sampling using sampleBy\n",
    "  // find all rows where answer_count in (5, 10, 20)\n",
    "  val dfQuestionsByAnswerCount = dfQuestions\n",
    "    .filter(\"owner_userid > 0\")\n",
    "    .filter(\"answer_count in (5, 10, 20)\")\n",
    "\n",
    "  // count how many rows match answer_count in (5, 10, 20)\n",
    "  dfQuestionsByAnswerCount\n",
    "    .groupBy(\"answer_count\")\n",
    "    .count()\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|answer_count|count|\n",
      "+------------+-----+\n",
      "|          20|   34|\n",
      "|           5|  400|\n",
      "|          10|   26|\n",
      "+------------+-----+\n",
      "\n",
      "+------------+-----+\n",
      "|answer_count|count|\n",
      "+------------+-----+\n",
      "|          20|   34|\n",
      "|           5|  388|\n",
      "|          10|   25|\n",
      "+------------+-----+\n",
      "\n",
      "Qauntiles segments = WrappedArray(-27.0, 2.0, 4443.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fractionKeyMap = Map(5 -> 0.5, 10 -> 0.1, 20 -> 1.0)\n",
       "quantiles = Array(-27.0, 2.0, 4443.0)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[-27.0, 2.0, 4443.0]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create a fraction map where we are only interested:\n",
    "  // - 50% of the rows that have answer_count = 5\n",
    "  // - 10% of the rows that have answer_count = 10\n",
    "  // - 100% of the rows that have answer_count = 20\n",
    "  // Note also that fractions should be in the range [0, 1]\n",
    "  val fractionKeyMap = Map(5 -> 0.5, 10 -> 0.1, 20 -> 1.0)\n",
    "\n",
    "  // Stratified sample using the fractionKeyMap.\n",
    "  dfQuestionsByAnswerCount\n",
    "    .stat\n",
    "    .sampleBy(\"answer_count\", fractionKeyMap, 7L)\n",
    "    .groupBy(\"answer_count\")\n",
    "    .count()\n",
    "    .show()\n",
    "\n",
    "  // Note that changing the random seed will modify your sampling outcome. As an example, let's change the random seed to 37.\n",
    "  dfQuestionsByAnswerCount\n",
    "    .stat\n",
    "    .sampleBy(\"answer_count\", fractionKeyMap, 37L)\n",
    "    .groupBy(\"answer_count\")\n",
    "    .count()\n",
    "    .show()\n",
    "\n",
    "\n",
    "  // Approximate Quantile\n",
    "  val quantiles = dfQuestions\n",
    "    .stat\n",
    "    .approxQuantile(\"score\", Array(0, 0.5, 1), 0.25)\n",
    "  println(s\"Qauntiles segments = ${quantiles.toSeq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bloom filter contains java tag = true\n",
      "bloom filter contains some unknown tag = false\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tagsBloomFilter = org.apache.spark.util.sketch.BloomFilterImpl@809c4023\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.util.sketch.BloomFilterImpl@809c4023"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tagsBloomFilter = dfTags.stat.bloomFilter(\"tag\", 1000L, 0.1)\n",
    "  println(s\"bloom filter contains java tag = ${tagsBloomFilter.mightContain(\"java\")}\")\n",
    "  println(s\"bloom filter contains some unknown tag = ${tagsBloomFilter.mightContain(\"unknown tag\")}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated frequency for tag java = 513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cmsTag = org.apache.spark.util.sketch.CountMinSketchImpl@431a88ed\n",
       "estimatedFrequency = 513\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "513"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " // Count Min Sketch\n",
    "  val cmsTag = dfTags.stat.countMinSketch(\"tag\", 0.1, 0.9, 37)\n",
    "  val estimatedFrequency = cmsTag.estimateCount(\"java\")\n",
    "  println(s\"Estimated frequency for tag java = $estimatedFrequency\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in sample dfTagsSample = 1948\n",
      "Number of rows in dfTags = 9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfTagsSample = [id: int, tag: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[id: int, tag: string]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  // Sampling With Replacement\n",
    "  val dfTagsSample = dfTags.sample(true, 0.2, 37L)\n",
    "  println(s\"Number of rows in sample dfTagsSample = ${dfTagsSample.count()}\")\n",
    "  println(s\"Number of rows in dfTags = ${dfTags.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
